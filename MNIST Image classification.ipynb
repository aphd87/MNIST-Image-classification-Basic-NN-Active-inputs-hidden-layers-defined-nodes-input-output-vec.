{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-9,  6,  1, -5,  4,  9,  4,  8, -3],\n",
       "       [ 9,  3, -8, -7,  6, -2, -3,  4, -7],\n",
       "       [-9,  8,  6,  5, -3, -3, -3,  4, -3],\n",
       "       [-5, -7, -2,  7, -5, -1,  1,  9, -5]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "input_nodes = 9\n",
    "hidden_nodes = 4\n",
    "output_nodes = 6\n",
    "wei_inp_hid = np.random.randint(-10, 10, (hidden_nodes, input_nodes))\n",
    "wei_inp_hid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 5, 6, 7, 8]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "active_input_percentage = 0.6\n",
    "active_input_nodes = int(input_nodes * active_input_percentage)\n",
    "active_input_indices = sorted(random.sample(range(0, input_nodes), \n",
    "                              active_input_nodes))\n",
    "active_input_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6,  9,  4,  8, -3],\n",
       "       [ 3, -2, -3,  4, -7],\n",
       "       [ 8, -3, -3,  4, -3],\n",
       "       [-7, -1,  1,  9, -5]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei_inp_hid_old = wei_inp_hid.copy()\n",
    "wei_inp_hid = wei_inp_hid[:, active_input_indices]\n",
    "wei_inp_hid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9 -1 -2 -3]\n",
      " [-7 -2  6  7]\n",
      " [ 2 -6  9 -6]\n",
      " [-5  0  5 -9]\n",
      " [ 8  9  0  3]\n",
      " [ 5  8 -3  9]]\n",
      "[0, 2]\n",
      "[[ 9 -2]\n",
      " [-7  6]\n",
      " [ 2  9]\n",
      " [-5  5]\n",
      " [ 8  0]\n",
      " [ 5 -3]]\n"
     ]
    }
   ],
   "source": [
    "wei_hid_out = np.random.randint(-10, 10, (output_nodes, hidden_nodes))\n",
    "print(wei_hid_out)\n",
    "active_hidden_percentage = 0.7\n",
    "active_hidden_nodes = int(hidden_nodes * active_hidden_percentage)\n",
    "active_hidden_indices = sorted(random.sample(range(0, hidden_nodes), \n",
    "                             active_hidden_nodes))\n",
    "print(active_hidden_indices)\n",
    "wei_hid_out_old = wei_hid_out.copy()\n",
    "wei_hid_out = wei_hid_out[:, active_hidden_indices]\n",
    "print(wei_hid_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6,  9,  4,  8, -3],\n",
       "       [ 8, -3, -3,  4, -3]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei_inp_hid = wei_inp_hid[active_hidden_indices]\n",
    "wei_inp_hid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wei_inp_hid: \n",
      " [[  1   1   6  -3  -3   1   0  -8   9   3]\n",
      " [ -2  -5 -10   4  -4   1   3   9  -8   2]\n",
      " [  8   6   4   3   4  -2   8   5   7   5]\n",
      " [  4   2 -10  -3   5  -1   5  -3   6   7]\n",
      " [  2  -2   3   4  -8  -1   5  -6   9  -3]]\n",
      "wei_hid_out:\n",
      " [[ -2  -8   6   9   6]\n",
      " [ -9   9   7   1  -6]\n",
      " [  2   3   0   3  -9]\n",
      " [  8   4 -10  -4  -8]\n",
      " [ -8  -4   6   9  -6]\n",
      " [ -7   5  -2  -3   4]\n",
      " [  3  -7   6  -8  -3]]\n",
      "\n",
      "active input indices:  [0, 1, 2, 3, 5, 6, 7]\n",
      "active hidden indices:  [0, 1, 3]\n",
      "\n",
      "weight_input_hidden after deactivating input nodes:\n",
      " [[  1   1   6  -3   1   0  -8]\n",
      " [ -2  -5 -10   4   1   3   9]\n",
      " [  8   6   4   3  -2   8   5]\n",
      " [  4   2 -10  -3  -1   5  -3]\n",
      " [  2  -2   3   4  -1   5  -6]]\n",
      "\n",
      "weight_input_hidden after deactivating hidden nodes:\n",
      " [[  1   1   6  -3   1   0  -8]\n",
      " [ -2  -5 -10   4   1   3   9]\n",
      " [  4   2 -10  -3  -1   5  -3]]\n",
      "\n",
      "weight_output_hidden after deactivating hidden nodes:\n",
      " [[-2 -8  9]\n",
      " [-9  9  1]\n",
      " [ 2  3  3]\n",
      " [ 8  4 -4]\n",
      " [-8 -4  9]\n",
      " [-7  5 -3]\n",
      " [ 3 -7 -8]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "input_nodes = 10\n",
    "hidden_nodes = 5\n",
    "output_nodes = 7\n",
    "wei_inp_hid = np.random.randint(-10, 10, (hidden_nodes, input_nodes))\n",
    "print(\"wei_inp_hid: \\n\", wei_inp_hid)\n",
    "wei_hid_out = np.random.randint(-10, 10, (output_nodes, hidden_nodes))\n",
    "print(\"wei_hid_out:\\n\", wei_hid_out)\n",
    "active_input_percentage = 0.7\n",
    "active_hidden_percentage = 0.7\n",
    "active_input_nodes = int(input_nodes * active_input_percentage)\n",
    "active_input_indices = sorted(random.sample(range(0, input_nodes), \n",
    "                              active_input_nodes))\n",
    "print(\"\\nactive input indices: \", active_input_indices)\n",
    "active_hidden_nodes = int(hidden_nodes * active_hidden_percentage)\n",
    "active_hidden_indices = sorted(random.sample(range(0, hidden_nodes), \n",
    "                             active_hidden_nodes))\n",
    "print(\"active hidden indices: \", active_hidden_indices)\n",
    "wei_inp_hid_old = wei_inp_hid.copy()\n",
    "wei_inp_hid = wei_inp_hid[:, active_input_indices]\n",
    "print(\"\\nweight_input_hidden after deactivating input nodes:\\n\", wei_inp_hid)\n",
    "wei_inp_hid = wei_inp_hid[active_hidden_indices]\n",
    "print(\"\\nweight_input_hidden after deactivating hidden nodes:\\n\", wei_inp_hid)\n",
    "wei_hid_out_old = wei_hid_out.copy()\n",
    "wei_hid_out = wei_hid_out[:, active_hidden_indices]\n",
    "print(\"\\nweight_output_hidden after deactivating hidden nodes:\\n\", wei_hid_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from scipy.special import expit as activation_function\n",
    "from scipy.stats import truncnorm\n",
    "def truncated_normal(mean=0, sd=1, low=0, upp=10):\n",
    "    return truncnorm(\n",
    "        (low - mean) / sd, (upp - mean) / sd, loc=mean, scale=sd)\n",
    "class NeuralNetwork:\n",
    "    \n",
    "    def __init__(self, \n",
    "                 no_of_in_nodes, \n",
    "                 no_of_out_nodes, \n",
    "                 no_of_hidden_nodes,\n",
    "                 learning_rate,\n",
    "                 bias=None\n",
    "                ):  \n",
    "        self.no_of_in_nodes = no_of_in_nodes\n",
    "        self.no_of_out_nodes = no_of_out_nodes       \n",
    "        self.no_of_hidden_nodes = no_of_hidden_nodes          \n",
    "        self.learning_rate = learning_rate \n",
    "        self.bias = bias\n",
    "        self.create_weight_matrices()\n",
    "        \n",
    "    def create_weight_matrices(self):\n",
    "        X = truncated_normal(mean=2, sd=1, low=-0.5, upp=0.5)\n",
    "        \n",
    "        bias_node = 1 if self.bias else 0\n",
    "        n = (self.no_of_in_nodes + bias_node) * self.no_of_hidden_nodes\n",
    "        X = truncated_normal(mean=2, sd=1, low=-0.5, upp=0.5)\n",
    "        self.wei_inp_hid = X.rvs(n).reshape((self.no_of_hidden_nodes, \n",
    "                                                   self.no_of_in_nodes + bias_node))\n",
    "        n = (self.no_of_hidden_nodes + bias_node) * self.no_of_out_nodes\n",
    "        X = truncated_normal(mean=2, sd=1, low=-0.5, upp=0.5)\n",
    "        self.wei_hid_out = X.rvs(n).reshape((self.no_of_out_nodes, \n",
    "                                                    (self.no_of_hidden_nodes + bias_node)))\n",
    "    def dropout_weight_matrices(self,\n",
    "                                active_input_percentage=0.70,\n",
    "                                active_hidden_percentage=0.70):\n",
    "        # restore wei_inp_hid array, if it had been used for dropout\n",
    "        self.wei_inp_hid_orig = self.wei_inp_hid.copy()\n",
    "        self.no_of_in_nodes_orig = self.no_of_in_nodes\n",
    "        self.no_of_hidden_nodes_orig = self.no_of_hidden_nodes\n",
    "        self.wei_hid_out_orig = self.wei_hid_out.copy()\n",
    "        \n",
    "        active_input_nodes = int(self.no_of_in_nodes * active_input_percentage)\n",
    "        active_input_indices = sorted(random.sample(range(0, self.no_of_in_nodes), \n",
    "                                      active_input_nodes))\n",
    "        active_hidden_nodes = int(self.no_of_hidden_nodes * active_hidden_percentage)\n",
    "        active_hidden_indices = sorted(random.sample(range(0, self.no_of_hidden_nodes), \n",
    "                                       active_hidden_nodes))\n",
    "        \n",
    "        self.wei_inp_hid = self.wei_inp_hid[:, active_input_indices][active_hidden_indices]       \n",
    "        self.wei_hid_out = self.wei_hid_out[:, active_hidden_indices]\n",
    "        \n",
    "        self.no_of_hidden_nodes = active_hidden_nodes\n",
    "        self.no_of_in_nodes = active_input_nodes\n",
    "        return active_input_indices, active_hidden_indices\n",
    "    \n",
    "    def weight_matrices_reset(self, \n",
    "                              active_input_indices, \n",
    "                              active_hidden_indices):\n",
    "        \n",
    "        \"\"\"\n",
    "        self.wei_inp_hid and self.wei_hid_out contain the newly adapted values from the active nodes.\n",
    "        We have to reconstruct the original weight matrices by assigning the new values \n",
    "        from the active nodes\n",
    "        \"\"\"\n",
    " \n",
    "        temp = self.wei_inp_hid_orig.copy()[:,active_input_indices]\n",
    "        temp[active_hidden_indices] = self.wei_inp_hid\n",
    "        self.wei_inp_hid_orig[:, active_input_indices] = temp\n",
    "        self.wei_inp_hid = self.wei_inp_hid_orig.copy()\n",
    "        self.wei_hid_out_orig[:, active_hidden_indices] = self.wei_hid_out\n",
    "        self.wei_hid_out = self.wei_hid_out_orig.copy()\n",
    "        self.no_of_in_nodes = self.no_of_in_nodes_orig\n",
    "        self.no_of_hidden_nodes = self.no_of_hidden_nodes_orig\n",
    " \n",
    "           \n",
    "    \n",
    "    def train_single(self, input_vector, target_vector):\n",
    "        \"\"\" \n",
    "        input_vector and target_vector can be tuple, list or ndarray\n",
    "        \"\"\"\n",
    " \n",
    "        if self.bias:\n",
    "            # adding bias node to the end of the input_vector\n",
    "            input_vector = np.concatenate( (input_vector, [self.bias]) )\n",
    "        input_vector = np.array(input_vector, ndmin=2).T\n",
    "        target_vector = np.array(target_vector, ndmin=2).T\n",
    "        output_vector1 = np.dot(self.wei_inp_hid, input_vector)\n",
    "        output_vector_hidden = activation_function(output_vector1)\n",
    "        \n",
    "        if self.bias:\n",
    "            output_vector_hidden = np.concatenate( (output_vector_hidden, [[self.bias]]) )\n",
    "        \n",
    "        output_vector2 = np.dot(self.wei_hid_out, output_vector_hidden)\n",
    "        output_vector_network = activation_function(output_vector2)\n",
    "        \n",
    "        output_errors = target_vector - output_vector_network\n",
    "        # update the weights:\n",
    "        tmp = output_errors * output_vector_network * (1.0 - output_vector_network)     \n",
    "        tmp = self.learning_rate  * np.dot(tmp, output_vector_hidden.T)\n",
    "        self.wei_hid_out += tmp\n",
    "        # calculate hidden errors:\n",
    "        hidden_errors = np.dot(self.wei_hid_out.T, output_errors)\n",
    "        # update the weights:\n",
    "        tmp = hidden_errors * output_vector_hidden * (1.0 - output_vector_hidden)\n",
    "        if self.bias:\n",
    "            x = np.dot(tmp, input_vector.T)[:-1,:] \n",
    "        else:\n",
    "            x = np.dot(tmp, input_vector.T)\n",
    "        self.wei_inp_hid += self.learning_rate * x\n",
    "            \n",
    "        \n",
    "    def train(self, data_array, \n",
    "              labels_one_hot_array,\n",
    "              epochs=1,\n",
    "              active_input_percentage=0.70,\n",
    "              active_hidden_percentage=0.70,\n",
    "              no_of_dropout_tests = 10):\n",
    "        partition_length = int(len(data_array) / no_of_dropout_tests)\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            print(\"epoch: \", epoch)\n",
    "            for start in range(0, len(data_array), partition_length):\n",
    "                active_in_indices, active_hidden_indices = \\\n",
    "                           self.dropout_weight_matrices(active_input_percentage,\n",
    "                                                        active_hidden_percentage)\n",
    "                for i in range(start, start + partition_length):\n",
    "                    self.train_single(data_array[i][active_in_indices], \n",
    "                                     labels_one_hot_array[i]) \n",
    "                    \n",
    "                self.weight_matrices_reset(active_in_indices, active_hidden_indices)\n",
    "      \n",
    "    \n",
    "    def confusion_matrix(self, data_array, labels):\n",
    "        cm = {}\n",
    "        for i in range(len(data_array)):\n",
    "            res = self.run(data_array[i])\n",
    "            res_max = res.argmax()\n",
    "            target = labels[i][0]\n",
    "            if (target, res_max) in cm:\n",
    "                cm[(target, res_max)] += 1\n",
    "            else:\n",
    "                cm[(target, res_max)] = 1\n",
    "        return cm\n",
    "        \n",
    "    \n",
    "    def run(self, input_vector):\n",
    "        # input_vector can be tuple, list or ndarray\n",
    "        \n",
    "        if self.bias:\n",
    "            # adding bias node to the end of the input_vector\n",
    "            input_vector = np.concatenate( (input_vector, [self.bias]) )\n",
    "        input_vector = np.array(input_vector, ndmin=2).T\n",
    "        output_vector = np.dot(self.wei_inp_hid, input_vector)\n",
    "        output_vector = activation_function(output_vector)\n",
    "        \n",
    "        if self.bias:\n",
    "            output_vector = np.concatenate( (output_vector, [[self.bias]]) )\n",
    "            \n",
    "        output_vector = np.dot(self.wei_hid_out, output_vector)\n",
    "        output_vector = activation_function(output_vector)\n",
    "    \n",
    "        return output_vector\n",
    "    \n",
    "    \n",
    "    def evaluate(self, data, labels):\n",
    "        corrects, wrongs = 0, 0\n",
    "        for i in range(len(data)):\n",
    "            res = self.run(data[i])\n",
    "            res_max = res.argmax()\n",
    "            if res_max == labels[i]:\n",
    "                corrects += 1\n",
    "            else:\n",
    "                wrongs += 1\n",
    "        return corrects, wrongs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7., 0., 0., ..., 0., 0., 0.],\n",
       "       [2., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [9., 0., 0., ..., 0., 0., 0.],\n",
       "       [5., 0., 0., ..., 0., 0., 0.],\n",
       "       [9., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "image_size = 28 # width and length\n",
    "no_of_different_labels = 10 #  i.e. 0, 1, 2, 3, ..., 9\n",
    "image_pixels = image_size * image_size\n",
    "train_data = np.loadtxt(\"mnist_train.csv\", \n",
    "                        delimiter=\",\")\n",
    "test_data = np.loadtxt(\"mnist_test.csv\", \n",
    "                       delimiter=\",\") \n",
    "test_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 785)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[test_data==255]\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "fac = 0.99 / 255\n",
    "train_imgs = np.asfarray(train_data[:, 1:]) * fac + 0.01\n",
    "test_imgs = np.asfarray(test_data[:, 1:]) * fac + 0.01\n",
    "train_labels = np.asfarray(train_data[:, :1])\n",
    "test_labels = np.asfarray(test_data[:, :1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label:  0  in one-hot representation:  [1 0 0 0 0 0 0 0 0 0]\n",
      "label:  1  in one-hot representation:  [0 1 0 0 0 0 0 0 0 0]\n",
      "label:  2  in one-hot representation:  [0 0 1 0 0 0 0 0 0 0]\n",
      "label:  3  in one-hot representation:  [0 0 0 1 0 0 0 0 0 0]\n",
      "label:  4  in one-hot representation:  [0 0 0 0 1 0 0 0 0 0]\n",
      "label:  5  in one-hot representation:  [0 0 0 0 0 1 0 0 0 0]\n",
      "label:  6  in one-hot representation:  [0 0 0 0 0 0 1 0 0 0]\n",
      "label:  7  in one-hot representation:  [0 0 0 0 0 0 0 1 0 0]\n",
      "label:  8  in one-hot representation:  [0 0 0 0 0 0 0 0 1 0]\n",
      "label:  9  in one-hot representation:  [0 0 0 0 0 0 0 0 0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\19144\\AppData\\Local\\Temp\\ipykernel_1856\\699995814.py:4: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  one_hot = (lr==label).astype(np.int)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "lr = np.arange(10)\n",
    "for label in range(10):\n",
    "    one_hot = (lr==label).astype(np.int)\n",
    "    print(\"label: \", label, \" in one-hot representation: \", one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\19144\\AppData\\Local\\Temp\\ipykernel_1856\\2912545453.py:3: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  train_labels_one_hot = (lr==train_labels).astype(np.float)\n",
      "C:\\Users\\19144\\AppData\\Local\\Temp\\ipykernel_1856\\2912545453.py:4: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  test_labels_one_hot = (lr==test_labels).astype(np.float)\n"
     ]
    }
   ],
   "source": [
    "lr = np.arange(no_of_different_labels)\n",
    "# transform labels into one hot representation\n",
    "train_labels_one_hot = (lr==train_labels).astype(np.float)\n",
    "test_labels_one_hot = (lr==test_labels).astype(np.float)\n",
    "# we don't want zeroes and ones in the labels neither:\n",
    "train_labels_one_hot[train_labels_one_hot==0] = 0.01\n",
    "train_labels_one_hot[train_labels_one_hot==1] = 0.99\n",
    "test_labels_one_hot[test_labels_one_hot==0] = 0.01\n",
    "test_labels_one_hot[test_labels_one_hot==1] = 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 28 # width and length\n",
    "no_of_different_labels = 10 #  i.e. 0, 1, 2, 3, ..., 9\n",
    "image_pixels = image_size * image_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000\n",
      "0 6000\n",
      "6000 12000\n",
      "12000 18000\n",
      "18000 24000\n",
      "24000 30000\n",
      "30000 36000\n",
      "36000 42000\n",
      "42000 48000\n",
      "48000 54000\n",
      "54000 60000\n"
     ]
    }
   ],
   "source": [
    "parts = 10\n",
    "partition_length = int(len(train_imgs) / parts)\n",
    "print(partition_length)\n",
    "start = 0\n",
    "for start in range(0, len(train_imgs), partition_length):\n",
    "    print(start, start + partition_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0\n",
      "epoch:  1\n",
      "epoch:  2\n"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "simple_network = NeuralNetwork(no_of_in_nodes = image_pixels, \n",
    "                               no_of_out_nodes = 10, \n",
    "                               no_of_hidden_nodes = 100,\n",
    "                               learning_rate = 0.1)\n",
    "    \n",
    "    \n",
    " \n",
    "simple_network.train(train_imgs, \n",
    "                     train_labels_one_hot, \n",
    "                     active_input_percentage=1,\n",
    "                     active_hidden_percentage=1,\n",
    "                     no_of_dropout_tests = 100,\n",
    "                     epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accruracy train:  0.9068833333333334\n",
      "accruracy: test 0.9119\n"
     ]
    }
   ],
   "source": [
    "corrects, wrongs = simple_network.evaluate(train_imgs, train_labels)\n",
    "print(\"accruracy train: \", corrects / ( corrects + wrongs))\n",
    "corrects, wrongs = simple_network.evaluate(test_imgs, test_labels)\n",
    "print(\"accruracy: test\", corrects / ( corrects + wrongs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
